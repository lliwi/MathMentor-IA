# Performance Optimizations - MathMentor IA

## üöÄ Optimizaciones Implementadas

Se han implementado las siguientes optimizaciones para mejorar significativamente la performance de generaci√≥n de ejercicios y b√∫squedas RAG:

### 1. **Singleton Pattern para RAG Service** ‚úÖ
- **Beneficio**: Elimina la carga repetida del modelo SentenceTransformer (2-5 segundos)
- **Implementaci√≥n**: [app/services/rag_service.py](app/services/rag_service.py)
- El modelo se carga una sola vez en memoria y se reutiliza para todas las peticiones

### 2. **Cach√© de Embeddings en Memoria (LRU)** ‚úÖ
- **Beneficio**: 30-50% reducci√≥n en tiempo de embeddings repetidos
- **Implementaci√≥n**: LRUCache en RAGService con capacidad para 1000 embeddings
- Los embeddings de queries frecuentes se cachean en memoria

### 3. **Batch Processing de Embeddings** ‚úÖ
- **Beneficio**: 3-5x m√°s r√°pido al procesar PDFs
- **Implementaci√≥n**: `store_chunks()` ahora procesa embeddings en lotes de 32
- Mejora dram√°tica en tiempo de procesamiento de libros

### 4. **Sistema de Cach√© con Redis** ‚úÖ
- **Beneficio**: 70-90% reducci√≥n de latencia en ejercicios/contextos cacheados
- **Implementaci√≥n**: [app/services/cache_service.py](app/services/cache_service.py)
- **TTL**:
  - Ejercicios: 1 hora (3600 segundos)
  - Contextos RAG: 2 horas (7200 segundos)
- Decoradores aplicados en:
  - `generate_exercise()` en OpenAI, DeepSeek y Ollama engines
  - `get_context_for_topic()` en RAG Service

### 5. **Connection Pooling de PostgreSQL** ‚úÖ
- **Beneficio**: 50-80% reducci√≥n en latencia de conexiones DB
- **Configuraci√≥n**:
  - `pool_size`: 10 conexiones
  - `max_overflow`: 20 conexiones adicionales
  - `pool_recycle`: 3600 segundos
  - `pool_pre_ping`: Verificaci√≥n autom√°tica de conexiones

### 6. **√çndices de Base de Datos** ‚úÖ
- **Beneficio**: 50-80% reducci√≥n en tiempo de b√∫squedas vectoriales
- **Implementaci√≥n**: Script [add_indexes.py](add_indexes.py)
- **√çndices creados**:
  - HNSW para b√∫squedas vectoriales (cosine similarity)
  - √çndices compuestos para queries frecuentes
  - Ver secci√≥n "Despliegue" para ejecutar

### 7. **Redis Container en Docker Compose** ‚úÖ
- **Implementaci√≥n**: [docker-compose.yml](docker-compose.yml)
- Redis 7 Alpine con persistencia
- Healthcheck autom√°tico
- Variables de entorno configuradas

## üìä Impacto Esperado

| Operaci√≥n | Antes | Despu√©s | Mejora |
|-----------|-------|---------|--------|
| Generaci√≥n de ejercicio (cache miss) | 5-8s | 4-6s | ~25% |
| Generaci√≥n de ejercicio (cache hit) | 5-8s | 0.1-0.5s | **~90%** |
| B√∫squeda RAG (cache miss) | 2-3s | 0.5-1s | ~60% |
| B√∫squeda RAG (cache hit) | 2-3s | 0.05s | **~98%** |
| Procesamiento PDF (100 chunks) | 60s | 15-20s | **~70%** |
| Conexi√≥n DB | 50-100ms | 5-10ms | ~85% |

## üõ†Ô∏è Despliegue

### 1. Actualizar Dependencias

```bash
# Instalar nuevas dependencias
docker-compose down
docker-compose build --no-cache
docker-compose up -d
```

### 2. Agregar √çndices de Base de Datos (IMPORTANTE)

**Ejecutar una sola vez despu√©s de desplegar:**

```bash
# Opci√≥n 1: Desde el contenedor
docker-compose exec web python add_indexes.py

# Opci√≥n 2: Localmente (si tienes Python configurado)
python add_indexes.py
```

Este script:
- Crea √≠ndice HNSW para b√∫squedas vectoriales (mejora dram√°tica)
- Agrega √≠ndices compuestos para queries frecuentes
- Es idempotente (seguro ejecutar m√∫ltiples veces)
- Muestra estad√≠sticas de √≠ndices creados

**‚ö†Ô∏è NOTA**: La creaci√≥n del √≠ndice HNSW puede tomar varios minutos en bases de datos grandes.

### 3. Verificar Redis

```bash
# Verificar que Redis est√° corriendo
docker-compose ps redis

# Ver logs de Redis
docker-compose logs redis

# Probar conexi√≥n
docker-compose exec redis redis-cli ping
# Deber√≠a responder: PONG
```

### 4. Monitoreo de Cach√©

```bash
# Ver estad√≠sticas de cach√© en Redis
docker-compose exec redis redis-cli INFO stats

# Ver keys cacheadas
docker-compose exec redis redis-cli KEYS "*"

# Limpiar cach√© (si necesario)
docker-compose exec redis redis-cli FLUSHDB
```

## üìà Monitoreo de Performance

### Ver Logs de Cach√©

Los logs mostrar√°n informaci√≥n sobre cache hits/misses:

```
[CacheService] Cache HIT for exercise: exercise:abc123...
[CacheService] Cache MISS for exercise: exercise:def456...
[RAGService] Initializing singleton with model: sentence-transformers/all-MiniLM-L6-v2
```

### Verificar √çndices en PostgreSQL

```bash
# Conectar a PostgreSQL
docker-compose exec db psql -U mathmentor_user -d mathmentor

# Ver √≠ndices
\di+

# Ver tama√±o de √≠ndices
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) as index_size
FROM pg_indexes
LEFT JOIN pg_class ON pg_class.relname = indexname
WHERE schemaname = 'public'
ORDER BY pg_relation_size(indexrelid) DESC;
```

## üîß Configuraci√≥n Avanzada

### Variables de Entorno (.env)

```bash
# Redis Configuration
REDIS_HOST=redis          # En docker: redis, Local: localhost
REDIS_PORT=6379
REDIS_DB=0

# RAG Configuration
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2

# Database Configuration (ya existe)
DATABASE_URL=postgresql://mathmentor_user:mathmentor_password@db:5432/mathmentor
```

### Ajustar TTL de Cach√©

En [app/services/cache_service.py](app/services/cache_service.py):

```python
@cache_service.cache_exercise(ttl=3600)  # Cambiar TTL aqu√≠ (en segundos)
@cache_service.cache_context(ttl=7200)   # Cambiar TTL aqu√≠ (en segundos)
```

### Ajustar Tama√±o de Pool de Conexiones

En [app/__init__.py](app/__init__.py):

```python
app.config['SQLALCHEMY_ENGINE_OPTIONS'] = {
    'pool_size': 10,        # Aumentar si hay muchos usuarios concurrentes
    'max_overflow': 20,     # Conexiones adicionales en picos
    # ...
}
```

### Optimizar Batch Size para Embeddings

En [app/services/rag_service.py](app/services/rag_service.py):

```python
def store_chunks(self, book_id: int, chunks: List[Dict], batch_size: int = 32):
    # Aumentar batch_size si tienes m√°s RAM disponible
    # batch_size = 64 o 128 para m√°quinas potentes
```

## üêõ Troubleshooting

### Redis no conecta

```bash
# Verificar si Redis est√° corriendo
docker-compose ps redis

# Reiniciar Redis
docker-compose restart redis

# Ver logs de error
docker-compose logs redis
```

**Soluci√≥n**: La aplicaci√≥n funcionar√° sin Redis (los decoradores fallan silenciosamente), pero sin cach√©.

### √çndices no se crean

```bash
# Verificar extensi√≥n pgvector
docker-compose exec db psql -U mathmentor_user -d mathmentor -c "SELECT * FROM pg_extension WHERE extname='vector';"

# Si no existe, crearla manualmente
docker-compose exec db psql -U mathmentor_user -d mathmentor -c "CREATE EXTENSION IF NOT EXISTS vector;"

# Ejecutar script de √≠ndices nuevamente
docker-compose exec web python add_indexes.py
```

### Performance no mejora

1. **Verificar que Redis est√° funcionando**:
   ```bash
   docker-compose logs redis | grep -i error
   ```

2. **Verificar √≠ndices creados**:
   ```bash
   docker-compose exec web python add_indexes.py
   ```

3. **Ver logs de cach√©**:
   ```bash
   docker-compose logs web | grep -i cache
   ```

4. **Limpiar cach√© y probar**:
   ```bash
   docker-compose exec redis redis-cli FLUSHDB
   ```

## üìù Notas T√©cnicas

### ¬øPor qu√© HNSW en lugar de IVFFlat?

- **HNSW** (Hierarchical Navigable Small World):
  - Mejor para datasets peque√±os/medianos (<1M vectores)
  - No requiere entrenamiento
  - B√∫squeda m√°s r√°pida en la mayor√≠a de casos
  - Usado en este proyecto

- **IVFFlat** (Inverted File):
  - Mejor para datasets muy grandes (>1M vectores)
  - Requiere entrenamiento con VACUUM ANALYZE
  - Menor precisi√≥n pero m√°s escalable

### Cach√© Multicapa

El sistema usa cach√© en 3 niveles:
1. **Memoria (LRUCache)**: Embeddings de texto (m√°s r√°pido)
2. **Redis**: Ejercicios y contextos completos (r√°pido, persistente)
3. **PostgreSQL**: Datos originales (m√°s lento, persistente)

### Seguridad del Cach√©

- Los ejercicios cacheados son los mismos para todos los estudiantes con los mismos par√°metros
- La clave de cach√© incluye: topic + difficulty + course
- No se cachea informaci√≥n personal del estudiante
- Los TTLs aseguran que el contenido se refresca peri√≥dicamente

## üöÄ Pr√≥ximos Pasos (Opcional)

Optimizaciones adicionales no implementadas que podr√≠as considerar:

1. **Modelo de Embedding m√°s ligero**: Cambiar a `paraphrase-MiniLM-L3-v2` (2x m√°s r√°pido)
2. **Async/Background Jobs**: Usar Celery/RQ para generaci√≥n as√≠ncrona
3. **CDN para Assets**: Servir archivos est√°ticos desde CDN
4. **Compresi√≥n Gzip**: Comprimir respuestas HTTP
5. **Prefetching**: Pre-generar contextos para temas populares

## üìö Referencias

- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [Redis Best Practices](https://redis.io/docs/management/optimization/)
- [SQLAlchemy Connection Pooling](https://docs.sqlalchemy.org/en/20/core/pooling.html)
- [Sentence Transformers Performance](https://www.sbert.net/docs/training/overview.html)
