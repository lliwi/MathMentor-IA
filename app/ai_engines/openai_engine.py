"""
OpenAI Engine implementation
"""
import os
import json
import time
from typing import Dict, Any
from openai import OpenAI
from app.ai_engines.base import AIEngine
from app.services.cache_service import cache_service


class OpenAIEngine(AIEngine):
    """OpenAI implementation of AI Engine"""

    def __init__(self, api_key: str = None, model: str = None, **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.model = model or os.getenv('ACTIVE_AI_MODEL', 'gpt-4')
        self.client = OpenAI(api_key=self.api_key)

    def _call_chat_completion(self, messages: list, temperature: float = 0.7) -> str:
        """Helper method to call OpenAI chat completion"""
        start_api = time.time()
        print(f"[AI-TIMING] Calling OpenAI API with model={self.model}, temperature={temperature}")
        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature
        )
        api_time = time.time() - start_api
        print(f"[AI-TIMING] OpenAI API call completed: {api_time:.2f}s")

        start_extract = time.time()
        content = response.choices[0].message.content
        extract_time = time.time() - start_extract
        print(f"[AI-TIMING] Extract response content: {extract_time:.3f}s")

        return content

    @cache_service.cache_exercise(ttl=3600)  # Cache for 1 hour
    def generate_exercise(self, topic: str, context: str, difficulty: str = 'medium', course: str = None, source_info: Dict[str, str] = None, existing_exercises: list = None, iteration: int = None) -> Dict[str, Any]:
        """Generate a math exercise using OpenAI with caching"""

        difficulty_map = {
            'easy': 'nivel b√°sico, conceptos fundamentales',
            'medium': 'nivel intermedio, requiere varios pasos',
            'hard': 'nivel avanzado, requiere pensamiento cr√≠tico'
        }

        # Add source information to the prompt
        source_text = ""
        if source_info:
            if source_info.get('type') == 'book':
                source_text = f"\nFuente: Libro '{source_info.get('title')}' ({source_info.get('course')} - {source_info.get('subject')})"
            elif source_info.get('type') == 'video':
                source_text = f"\nFuente: Video '{source_info.get('title')}' del canal {source_info.get('channel')}"

        # Add information about existing exercises to avoid duplicates
        existing_text = ""
        if existing_exercises:
            existing_text = "\n\nEJERCICIOS YA GENERADOS (NO REPETIR):\n"
            for idx, ex in enumerate(existing_exercises[:5], 1):  # Show last 5 exercises
                existing_text += f"{idx}. {ex[:200]}...\n"
            existing_text += "\nIMPORTANTE: El nuevo ejercicio debe ser COMPLETAMENTE DIFERENTE de los anteriores. Cambia tanto la situaci√≥n/contexto como los valores num√©ricos."

        iteration_text = f"\nEste es el ejercicio #{iteration} de la serie." if iteration else ""

        prompt = f"""Genera un ejercicio de matem√°ticas en JSON:

Tema: {topic}
Curso: {course or 'No especificado'}{source_text}
Dificultad: {difficulty_map.get(difficulty, 'medio')}
Contexto: {context[:500]}{iteration_text}{existing_text}

JSON esperado:
{{
    "content": "Enunciado del ejercicio",
    "solution": "Resultado final",
    "methodology": "Pasos de resoluci√≥n",
    "available_procedures": [
        {{"id": 1, "name": "Procedimiento", "description": "Qu√© es"}},
        {{"id": 2, "name": "Otro", "description": "Qu√© es"}}
    ],
    "expected_procedures": [1, 3]
}}

Requisitos:
- 4-6 procedimientos (algunos correctos, otros no)
- Descripciones de 1 l√≠nea m√°ximo
- Sin texto adicional fuera del JSON
- IMPORTANTE: En el enunciado, cuando el problema involucre magnitudes f√≠sicas (longitud, peso, tiempo, velocidad, √°rea, volumen, etc.), SIEMPRE especifica claramente: "Indica las unidades en tu respuesta" o "Expresa el resultado con sus unidades correspondientes"
- IMPORTANTE: Usa emoticonos apropiados para hacer el ejercicio m√°s divertido y motivador
  Ejemplos: üìê üìè üìä üî¢ ‚ûï ‚ûñ ‚úñÔ∏è ‚ûó üéØ üí° ü§î ‚≠ê üé® üìà üìâ üî∫ üîª ‚öñÔ∏è üé≤
- CR√çTICO: Genera un ejercicio √öNICO y ORIGINAL. Var√≠a la tem√°tica contextual (diferentes situaciones de la vida real, diferentes enfoques del problema). Usa valores num√©ricos completamente diferentes. NO repitas ejercicios similares a los ya generados."""

        messages = [
            {"role": "system", "content": "Eres un profesor de matem√°ticas experto en crear ejercicios did√°cticos."},
            {"role": "user", "content": prompt}
        ]

        response = self._call_chat_completion(messages, temperature=0.5)

        start_parse = time.time()
        try:
            # Extract JSON from response
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
            elif '```' in response:
                response = response.split('```')[1].split('```')[0].strip()

            exercise_data = json.loads(response)
            parse_time = time.time() - start_parse
            print(f"[AI-TIMING] JSON parsing: {parse_time:.3f}s")
            return exercise_data
        except json.JSONDecodeError:
            # Fallback if JSON parsing fails
            return {
                'content': response,
                'solution': '',
                'methodology': ''
            }

    def evaluate_submission(self, exercise: str, expected_solution: str, expected_methodology: str,
                          student_answer: str, student_methodology: str) -> Dict[str, Any]:
        """Evaluate student submission using OpenAI"""

        prompt = f"""Eval√∫a la soluci√≥n de un estudiante de matem√°ticas.

EJERCICIO:
{exercise}

SOLUCI√ìN CORRECTA (REFERENCIA √öNICA):
{expected_solution}

METODOLOG√çA ESPERADA:
{expected_methodology}

RESPUESTA DEL ESTUDIANTE:
{student_answer}

PROCEDIMIENTO DEL ESTUDIANTE:
{student_methodology}

INSTRUCCIONES CR√çTICAS:
- La "SOLUCI√ìN CORRECTA" mostrada arriba es LA √öNICA respuesta v√°lida
- Compara la respuesta del estudiante EXACTAMENTE con esta soluci√≥n
- NO reinterpretes ni recalcules el problema
- Si la respuesta del estudiante es matem√°ticamente equivalente a la soluci√≥n correcta, marca como correcta
- Considera variaciones de formato (ej: 0.5 = 1/2) como correctas

Eval√∫a y responde en formato JSON:
{{
    "is_correct_result": true/false,
    "is_correct_methodology": true/false,
    "errors_found": ["lista", "de", "errores"],
    "feedback": "Retroalimentaci√≥n breve"
}}

Criterios:
- is_correct_result: ¬øLa respuesta es matem√°ticamente equivalente a la SOLUCI√ìN CORRECTA?
- is_correct_methodology: ¬øEl procedimiento es correcto?
- errors_found: Lista espec√≠fica de errores encontrados
- feedback: Explicaci√≥n breve motivadora (se generar√° feedback detallado despu√©s si es necesario)

IMPORTANTE: Usa emoticonos apropiados para hacer el feedback m√°s amigable y motivador
Ejemplos: ‚úÖ ‚ùå üëç üí™ üéØ ‚≠ê ü§î üí° üìù ‚ú® üöÄ"""

        messages = [
            {"role": "system", "content": "Eres un profesor de matem√°ticas experto en evaluar trabajos. IMPORTANTE: Usa SIEMPRE la soluci√≥n proporcionada como referencia √∫nica. No recalcules ni reinterpretes el problema. Usa emoticonos para hacer el feedback m√°s motivador."},
            {"role": "user", "content": prompt}
        ]

        response = self._call_chat_completion(messages, temperature=0.2)

        try:
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
            elif '```' in response:
                response = response.split('```')[1].split('```')[0].strip()

            evaluation = json.loads(response)
            return evaluation
        except json.JSONDecodeError:
            return {
                'is_correct_result': False,
                'is_correct_methodology': False,
                'errors_found': ['Error al evaluar'],
                'feedback': response
            }

    def generate_feedback(self, exercise: str, expected_solution: str, student_answer: str,
                         student_methodology: str, errors: list, context: str = None) -> str:
        """Generate detailed feedback using OpenAI"""

        prompt = f"""Genera retroalimentaci√≥n did√°ctica detallada para un estudiante.

EJERCICIO:
{exercise}

SOLUCI√ìN CORRECTA (REFERENCIA √öNICA):
{expected_solution}

RESPUESTA DEL ESTUDIANTE:
{student_answer}

PROCEDIMIENTO DEL ESTUDIANTE:
{student_methodology}

ERRORES IDENTIFICADOS:
{', '.join(errors)}

INSTRUCCIONES CR√çTICAS:
- La "SOLUCI√ìN CORRECTA" es la √∫nica respuesta v√°lida
- Compara la respuesta del estudiante con esta soluci√≥n EXACTAMENTE
- NO recalcules el problema ni propongas soluciones alternativas
- Explica los errores bas√°ndote en la diferencia con la SOLUCI√ìN CORRECTA

Genera retroalimentaci√≥n que:
1. Identifique espec√≠ficamente d√≥nde est√° el error
2. Explique por qu√© es incorrecto comparando con la SOLUCI√ìN CORRECTA
3. Gu√≠e al estudiante hacia la soluci√≥n correcta sin resolverlo completamente
4. Use un tono motivador y educativo
5. Sea concisa pero completa (m√°ximo 200 palabras)
6. IMPORTANTE: Incluye emoticonos apropiados para hacer el feedback m√°s divertido y motivador
   Ejemplos: üí° ü§î ‚ú® üìù üëÄ ‚ö†Ô∏è üí™ üéØ ‚úÖ üìê üîç üí≠ üåü"""

        messages = [
            {"role": "system", "content": "Eres un tutor de matem√°ticas paciente y did√°ctico. IMPORTANTE: Usa SIEMPRE la soluci√≥n proporcionada como referencia √∫nica. No recalcules el problema. Usa emoticonos para hacer el feedback m√°s amigable."},
            {"role": "user", "content": prompt}
        ]

        return self._call_chat_completion(messages, temperature=0.5)

    def generate_hint(self, exercise: str, context: str = None) -> str:
        """Generate a hint using OpenAI"""

        prompt = f"""Genera una pista √∫til para ayudar a resolver este ejercicio de matem√°ticas:

EJERCICIO:
{exercise}

La pista debe:
- Orientar sin revelar la soluci√≥n completa
- Sugerir el primer paso o concepto clave
- Ser breve (m√°ximo 50 palabras)
- Motivar al estudiante a pensar por s√≠ mismo
- IMPORTANTE: Incluye emoticonos apropiados para hacer la pista m√°s divertida y motivadora
  Ejemplos: üí° ü§î üéØ üëÄ ‚ú® üîç üí≠ üåü üìù üöÄ"""

        messages = [
            {"role": "system", "content": "Eres un tutor de matem√°ticas que da pistas √∫tiles sin revelar la soluci√≥n. Usa emoticonos para hacer las pistas m√°s amigables."},
            {"role": "user", "content": prompt}
        ]

        return self._call_chat_completion(messages, temperature=0.7)

    def extract_topics(self, text_chunks: list, book_metadata: Dict[str, str]) -> list:
        """Extract topics from book chunks using OpenAI"""
        import sys

        print(f"[DEBUG OpenAI] Extrayendo temas de {len(text_chunks)} chunks", flush=True)
        print(f"[DEBUG OpenAI] Metadata: {book_metadata}", flush=True)
        sys.stdout.flush()

        # Combine first 10 chunks to get table of contents or main structure
        sample_text = '\n\n'.join(text_chunks[:10])
        print(f"[DEBUG OpenAI] Longitud del texto de muestra: {len(sample_text)} caracteres", flush=True)
        print(f"[DEBUG OpenAI] Primeros 500 caracteres del texto:", flush=True)
        print(sample_text[:500], flush=True)
        sys.stdout.flush()

        prompt = f"""Extrae los temas y subtemas de este libro de matem√°ticas en formato JSON.

LIBRO: {book_metadata.get('title', 'Sin t√≠tulo')}
CURSO: {book_metadata.get('course', 'No especificado')}
MATERIA: {book_metadata.get('subject', 'Matem√°ticas')}

TEXTO:
{sample_text}

Formato de respuesta esperado:
{{
    "topics": [
        {{"name": "Nombre del tema", "description": "Breve descripci√≥n"}},
        ...
    ]
}}

Busca especialmente en el √≠ndice o tabla de contenidos si est√° presente."""

        messages = [
            {"role": "system", "content": "Eres un experto en an√°lisis de contenido educativo."},
            {"role": "user", "content": prompt}
        ]

        print(f"[DEBUG OpenAI] Llamando a OpenAI con modelo: {self.model}", flush=True)
        sys.stdout.flush()
        response = self._call_chat_completion(messages, temperature=0.3)

        print(f"[DEBUG OpenAI] ===== RESPUESTA CRUDA DE OPENAI =====", flush=True)
        print(f"[DEBUG OpenAI] Tipo: {type(response)}", flush=True)
        print(f"[DEBUG OpenAI] Longitud: {len(response)}", flush=True)
        print(f"[DEBUG OpenAI] Contenido completo:", flush=True)
        print(response, flush=True)
        print(f"[DEBUG OpenAI] ====================================", flush=True)
        sys.stdout.flush()

        try:
            original_response = response
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
                print(f"[DEBUG OpenAI] JSON extra√≠do de bloque markdown con ```json", flush=True)
            elif '```' in response:
                response = response.split('```')[1].split('```')[0].strip()
                print(f"[DEBUG OpenAI] JSON extra√≠do de bloque markdown con ```", flush=True)

            print(f"[DEBUG OpenAI] JSON a parsear:", flush=True)
            print(response, flush=True)
            sys.stdout.flush()

            data = json.loads(response)
            print(f"[DEBUG OpenAI] JSON parseado correctamente: {data}", flush=True)

            topics = data.get('topics', [])
            print(f"[DEBUG OpenAI] Temas extra√≠dos: {len(topics)}", flush=True)
            print(f"[DEBUG OpenAI] Lista de temas: {topics}", flush=True)
            sys.stdout.flush()

            return topics
        except json.JSONDecodeError as e:
            print(f"[DEBUG OpenAI] ERROR al parsear JSON: {str(e)}", flush=True)
            print(f"[DEBUG OpenAI] Respuesta original: {original_response}", flush=True)
            sys.stdout.flush()
            return []

    @cache_service.cache_summary(ttl=86400)  # Cache for 24 hours
    def generate_topic_summary(self, topic: str, context: str, course: str = None, source_info: Dict[str, str] = None) -> str:
        """Generate a comprehensive topic summary using OpenAI with caching"""

        # Add source information to the prompt
        source_text = ""
        if source_info:
            if source_info.get('type') == 'book':
                source_text = f"\nFUENTE: Libro '{source_info.get('title')}' ({source_info.get('course')} - {source_info.get('subject')})"
            elif source_info.get('type') == 'video':
                source_text = f"\nFUENTE: Video '{source_info.get('title')}' del canal {source_info.get('channel')}"

        prompt = f"""Eres un profesor de matem√°ticas experto. Genera un resumen de estudio completo y did√°ctico sobre el siguiente tema:

TEMA: {topic}
CURSO: {course or 'No especificado'}{source_text}

CONTENIDO DEL LIBRO DE TEXTO:
{context}

Genera un resumen bien estructurado que incluya:

1. **Conceptos Clave**: Lista los conceptos fundamentales del tema
2. **Definiciones Importantes**: Define los t√©rminos t√©cnicos relevantes
3. **F√≥rmulas y Propiedades**: Enumera las f√≥rmulas principales y propiedades matem√°ticas
4. **Procedimientos**: Explica paso a paso los procedimientos comunes
5. **Ejemplos Resueltos**: Incluye 1-2 ejemplos completamente resueltos
6. **Consejos y Trucos**: A√±ade tips √∫tiles para recordar conceptos o evitar errores comunes
7. **Relaci√≥n con Otros Temas**: Menciona c√≥mo se relaciona con otros conceptos matem√°ticos

El resumen debe:
- Ser claro y did√°ctico
- Usar formato Markdown para una mejor presentaci√≥n
- Ser comprensible para estudiantes del nivel especificado
- Tener una longitud apropiada (800-1200 palabras)
- Incluir ejemplos pr√°cticos y visuales cuando sea posible
- Estar basado en el contenido del libro proporcionado
- IMPORTANTE: Incluye emoticonos apropiados para hacer el resumen m√°s visual y atractivo
  Ejemplos: üìê üìä üî¢ ‚ûï ‚ûñ ‚úñÔ∏è ‚ûó üí° üéØ ‚≠ê ‚ú® üìù üîç üí≠ üìà üìâ ‚öñÔ∏è üé≤ üåü üí™ ‚úÖ

Formato del resumen: Markdown con secciones bien diferenciadas."""

        messages = [
            {"role": "system", "content": "Eres un profesor de matem√°ticas experto en crear materiales de estudio did√°cticos y completos. Usa emoticonos para hacer el contenido m√°s visual y atractivo."},
            {"role": "user", "content": prompt}
        ]

        return self._call_chat_completion(messages, temperature=0.7)

    def generate_visual_scheme(self, exercise: str, context: str = None) -> str:
        """Generate a visual scheme using Mermaid diagram syntax"""

        prompt = f"""Genera un esquema visual usando sintaxis Mermaid para ayudar a resolver este ejercicio de matem√°ticas:

EJERCICIO:
{exercise}

Crea un diagrama Mermaid que:
- Represente visualmente la estructura del problema
- Muestre las relaciones entre los datos conocidos y desconocidos
- Sugiera el flujo l√≥gico de resoluci√≥n SIN resolverlo
- Use el tipo de diagrama m√°s apropiado (flowchart, graph, etc.)

REGLAS IMPORTANTES:
- NO incluyas c√°lculos espec√≠ficos ni resultados num√©ricos
- NO resuelvas el problema, solo muestra el camino
- Usa placeholders gen√©ricos como "Calcular X", "Aplicar f√≥rmula Y"
- El estudiante debe poder usar el diagrama para pensar por s√≠ mismo
- Mant√©n el diagrama orientativo, no resolutivo

FORMATO:
- Devuelve SOLO el c√≥digo Mermaid, sin explicaciones adicionales
- No incluyas bloques de c√≥digo markdown (```mermaid)
- Empieza directamente con el tipo de diagrama (ej: graph TD, flowchart LR, etc.)
- Usa etiquetas claras y concisas en espa√±ol

Ejemplo de formato esperado:
graph TD
    A[Datos del problema] --> B[Identificar qu√© se busca]
    B --> C[Aplicar concepto clave]
    C --> D[Realizar operaciones]
    D --> E[Verificar resultado]"""

        messages = [
            {"role": "system", "content": "Eres un experto en visualizaci√≥n de problemas matem√°ticos que crea diagramas Mermaid claros y did√°cticos."},
            {"role": "user", "content": prompt}
        ]

        response = self._call_chat_completion(messages, temperature=0.5)

        # Clean up response - remove markdown code blocks if present
        if '```mermaid' in response:
            response = response.split('```mermaid')[1].split('```')[0].strip()
        elif '```' in response:
            response = response.split('```')[1].split('```')[0].strip()

        return response.strip()
