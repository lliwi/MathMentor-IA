"""
DeepSeek Engine implementation
"""
import os
import json
import time
import requests
from typing import Dict, Any
from app.ai_engines.base import AIEngine
from app.services.cache_service import cache_service


class DeepSeekEngine(AIEngine):
    """DeepSeek implementation of AI Engine (compatible with OpenAI API)"""

    def __init__(self, api_key: str = None, model: str = None, **kwargs):
        super().__init__(api_key, model, **kwargs)
        self.api_key = api_key or os.getenv('DEEPSEEK_API_KEY')
        self.model = model or 'deepseek-chat'
        self.base_url = 'https://api.deepseek.com/v1'

    def _call_chat_completion(self, messages: list, temperature: float = 0.7) -> str:
        """Helper method to call DeepSeek chat completion"""
        start_api = time.time()
        print(f"[AI-TIMING] Calling DeepSeek API with model={self.model}, temperature={temperature}")

        headers = {
            'Authorization': f'Bearer {self.api_key}',
            'Content-Type': 'application/json'
        }

        data = {
            'model': self.model,
            'messages': messages,
            'temperature': temperature
        }

        response = requests.post(
            f'{self.base_url}/chat/completions',
            headers=headers,
            json=data,
            timeout=60  # 60 second timeout
        )
        response.raise_for_status()

        api_time = time.time() - start_api
        print(f"[AI-TIMING] DeepSeek API call completed: {api_time:.2f}s")

        start_extract = time.time()
        content = response.json()['choices'][0]['message']['content']
        extract_time = time.time() - start_extract
        print(f"[AI-TIMING] Extract response content: {extract_time:.3f}s")

        return content

    @cache_service.cache_exercise(ttl=3600)  # Cache for 1 hour
    def generate_exercise(self, topic: str, context: str, difficulty: str = 'medium', course: str = None) -> Dict[str, Any]:
        """Generate exercise with caching - same logic as OpenAI"""
        difficulty_map = {
            'easy': 'nivel b√°sico, conceptos fundamentales',
            'medium': 'nivel intermedio, requiere varios pasos',
            'hard': 'nivel avanzado, requiere pensamiento cr√≠tico'
        }

        prompt = f"""Genera un ejercicio de matem√°ticas en JSON:

Tema: {topic}
Curso: {course or 'No especificado'}
Dificultad: {difficulty_map.get(difficulty, 'medio')}
Contexto: {context[:500]}

JSON esperado:
{{
    "content": "Enunciado del ejercicio",
    "solution": "Resultado final",
    "methodology": "Pasos de resoluci√≥n",
    "available_procedures": [
        {{"id": 1, "name": "Procedimiento", "description": "Qu√© es"}},
        {{"id": 2, "name": "Otro", "description": "Qu√© es"}}
    ],
    "expected_procedures": [1, 3]
}}

Requisitos:
- 4-6 procedimientos (algunos correctos, otros no)
- Descripciones de 1 l√≠nea m√°ximo
- Sin texto adicional fuera del JSON
- IMPORTANTE: En el enunciado, cuando el problema involucre magnitudes f√≠sicas (longitud, peso, tiempo, velocidad, √°rea, volumen, etc.), SIEMPRE especifica claramente: "Indica las unidades en tu respuesta" o "Expresa el resultado con sus unidades correspondientes"
- IMPORTANTE: Usa emoticonos apropiados para hacer el ejercicio m√°s divertido y motivador
  Ejemplos: üìê üìè üìä üî¢ ‚ûï ‚ûñ ‚úñÔ∏è ‚ûó üéØ üí° ü§î ‚≠ê üé® üìà üìâ üî∫ üîª ‚öñÔ∏è üé≤"""

        messages = [
            {"role": "system", "content": "Eres un profesor de matem√°ticas experto. Usa emoticonos para hacer el contenido m√°s visual y atractivo."},
            {"role": "user", "content": prompt}
        ]

        response = self._call_chat_completion(messages, temperature=0.5)

        start_parse = time.time()
        try:
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
            exercise_data = json.loads(response)
            parse_time = time.time() - start_parse
            print(f"[AI-TIMING] JSON parsing: {parse_time:.3f}s")
            return exercise_data
        except:
            return {'content': response, 'solution': '', 'methodology': ''}

    def evaluate_submission(self, exercise: str, expected_solution: str, expected_methodology: str,
                          student_answer: str, student_methodology: str) -> Dict[str, Any]:
        """Evaluate submission with coherent reference"""
        prompt = f"""Eval√∫a la soluci√≥n de un estudiante.

EJERCICIO: {exercise}

SOLUCI√ìN CORRECTA (REFERENCIA √öNICA): {expected_solution}

RESPUESTA ESTUDIANTE: {student_answer}

INSTRUCCIONES CR√çTICAS:
- La "SOLUCI√ìN CORRECTA" es LA √öNICA respuesta v√°lida
- NO recalcules el problema
- Compara la respuesta del estudiante con esta soluci√≥n EXACTAMENTE
- IMPORTANTE: Usa emoticonos apropiados para hacer el feedback m√°s amigable y motivador
  Ejemplos: ‚úÖ ‚ùå üëç üí™ üéØ ‚≠ê ü§î üí° üìù ‚ú® üöÄ

Responde en JSON: {{"is_correct_result": bool, "is_correct_methodology": bool, "errors_found": [], "feedback": ""}}"""

        messages = [
            {"role": "system", "content": "Eres un profesor evaluador. IMPORTANTE: Usa SIEMPRE la soluci√≥n proporcionada como referencia √∫nica. Usa emoticonos para hacer el feedback m√°s amigable."},
            {"role": "user", "content": prompt}
        ]

        response = self._call_chat_completion(messages, temperature=0.2)

        try:
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
            return json.loads(response)
        except:
            return {
                'is_correct_result': False,
                'is_correct_methodology': False,
                'errors_found': [],
                'feedback': response
            }

    def generate_feedback(self, exercise: str, expected_solution: str, student_answer: str,
                         student_methodology: str, errors: list, context: str = None) -> str:
        """Generate feedback with coherent reference"""
        prompt = f"""Genera retroalimentaci√≥n did√°ctica.

EJERCICIO: {exercise}

SOLUCI√ìN CORRECTA (REFERENCIA √öNICA): {expected_solution}

RESPUESTA ESTUDIANTE: {student_answer}

ERRORES: {', '.join(errors)}

INSTRUCCIONES:
- Compara con la SOLUCI√ìN CORRECTA √∫nicamente
- NO recalcules el problema
- Explica los errores bas√°ndote en la diferencia con la soluci√≥n correcta
- IMPORTANTE: Usa emoticonos apropiados para hacer el feedback m√°s amigable y motivador
  Ejemplos: üí° ü§î ‚ú® üìù üëÄ ‚ö†Ô∏è üí™ üéØ ‚≠ê üöÄ ‚úÖ üìö"""

        messages = [
            {"role": "system", "content": "Eres un tutor paciente. IMPORTANTE: Usa la soluci√≥n proporcionada como referencia √∫nica. Usa emoticonos para hacer el feedback m√°s visual y motivador."},
            {"role": "user", "content": prompt}
        ]

        return self._call_chat_completion(messages, temperature=0.5)

    def generate_hint(self, exercise: str, context: str = None) -> str:
        """Generate hint"""
        prompt = f"""Genera una pista breve para ayudar a resolver este ejercicio sin dar la soluci√≥n:

EJERCICIO:
{exercise}

INSTRUCCIONES:
- Proporciona una pista orientadora, no resuelvas el problema
- Mant√©n la pista breve y concisa
- IMPORTANTE: Usa emoticonos apropiados para hacer la pista m√°s amigable y motivadora
  Ejemplos: üí° ü§î üéØ üëÄ ‚ú® üîç üí≠ üåü üìå üîë"""
        messages = [
            {"role": "system", "content": "Eres un tutor que da pistas √∫tiles. Usa emoticonos para hacer las pistas m√°s visuales y motivadoras."},
            {"role": "user", "content": prompt}
        ]
        return self._call_chat_completion(messages, temperature=0.7)

    def extract_topics(self, text_chunks: list, book_metadata: Dict[str, str]) -> list:
        """Extract topics from book chunks using DeepSeek"""
        import sys

        print(f"[DEBUG DeepSeek] Extrayendo temas de {len(text_chunks)} chunks", flush=True)
        print(f"[DEBUG DeepSeek] Metadata: {book_metadata}", flush=True)
        sys.stdout.flush()

        # Combine first 10 chunks to get table of contents or main structure
        sample_text = '\n\n'.join(text_chunks[:10])
        print(f"[DEBUG DeepSeek] Longitud del texto de muestra: {len(sample_text)} caracteres", flush=True)
        print(f"[DEBUG DeepSeek] Primeros 500 caracteres del texto:", flush=True)
        print(sample_text[:500], flush=True)
        sys.stdout.flush()

        prompt = f"""Extrae los temas y subtemas de este libro de matem√°ticas en formato JSON.

LIBRO: {book_metadata.get('title', 'Sin t√≠tulo')}
CURSO: {book_metadata.get('course', 'No especificado')}
MATERIA: {book_metadata.get('subject', 'Matem√°ticas')}

TEXTO:
{sample_text}

Formato de respuesta esperado:
{{
    "topics": [
        {{"name": "Nombre del tema", "description": "Breve descripci√≥n"}},
        ...
    ]
}}

Busca especialmente en el √≠ndice o tabla de contenidos si est√° presente."""

        messages = [
            {"role": "system", "content": "Eres un experto en an√°lisis de contenido educativo."},
            {"role": "user", "content": prompt}
        ]

        print(f"[DEBUG DeepSeek] Llamando a DeepSeek con modelo: {self.model}", flush=True)
        sys.stdout.flush()

        try:
            response = self._call_chat_completion(messages, temperature=0.3)

            print(f"[DEBUG DeepSeek] ===== RESPUESTA CRUDA DE DEEPSEEK =====", flush=True)
            print(f"[DEBUG DeepSeek] Tipo: {type(response)}", flush=True)
            print(f"[DEBUG DeepSeek] Longitud: {len(response)}", flush=True)
            print(f"[DEBUG DeepSeek] Contenido completo:", flush=True)
            print(response, flush=True)
            print(f"[DEBUG DeepSeek] ====================================", flush=True)
            sys.stdout.flush()

            original_response = response
            if '```json' in response:
                response = response.split('```json')[1].split('```')[0].strip()
                print(f"[DEBUG DeepSeek] JSON extra√≠do de bloque markdown con ```json", flush=True)
            elif '```' in response:
                response = response.split('```')[1].split('```')[0].strip()
                print(f"[DEBUG DeepSeek] JSON extra√≠do de bloque markdown con ```", flush=True)

            print(f"[DEBUG DeepSeek] JSON a parsear:", flush=True)
            print(response, flush=True)
            sys.stdout.flush()

            data = json.loads(response)
            print(f"[DEBUG DeepSeek] JSON parseado correctamente: {data}", flush=True)

            topics = data.get('topics', [])
            print(f"[DEBUG DeepSeek] Temas extra√≠dos: {len(topics)}", flush=True)
            print(f"[DEBUG DeepSeek] Lista de temas: {topics}", flush=True)
            sys.stdout.flush()

            return topics
        except requests.exceptions.RequestException as e:
            print(f"[DEBUG DeepSeek] ERROR en la petici√≥n HTTP: {str(e)}", flush=True)
            sys.stdout.flush()
            return []
        except json.JSONDecodeError as e:
            print(f"[DEBUG DeepSeek] ERROR al parsear JSON: {str(e)}", flush=True)
            print(f"[DEBUG DeepSeek] Respuesta original: {original_response if 'original_response' in locals() else 'N/A'}", flush=True)
            sys.stdout.flush()
            return []
        except Exception as e:
            print(f"[DEBUG DeepSeek] ERROR inesperado: {type(e).__name__}: {str(e)}", flush=True)
            sys.stdout.flush()
            return []

    @cache_service.cache_summary(ttl=86400)
    def generate_topic_summary(self, topic: str, context: str, course: str = None) -> str:
        """Generate a comprehensive topic summary using DeepSeek with caching"""

        prompt = f"""Eres un profesor de matem√°ticas experto. Genera un resumen de estudio completo y did√°ctico sobre el siguiente tema:

TEMA: {topic}
CURSO: {course or 'No especificado'}

CONTENIDO DEL LIBRO DE TEXTO:
{context}

Genera un resumen bien estructurado que incluya:

1. **Conceptos Clave**: Lista los conceptos fundamentales del tema
2. **Definiciones Importantes**: Define los t√©rminos t√©cnicos relevantes
3. **F√≥rmulas y Propiedades**: Enumera las f√≥rmulas principales y propiedades matem√°ticas
4. **Procedimientos**: Explica paso a paso los procedimientos comunes
5. **Ejemplos Resueltos**: Incluye 1-2 ejemplos completamente resueltos
6. **Consejos y Trucos**: A√±ade tips √∫tiles para recordar conceptos o evitar errores comunes
7. **Relaci√≥n con Otros Temas**: Menciona c√≥mo se relaciona con otros conceptos matem√°ticos

El resumen debe:
- Ser claro y did√°ctico
- Usar formato Markdown para una mejor presentaci√≥n
- Ser comprensible para estudiantes del nivel especificado
- Tener una longitud apropiada (800-1200 palabras)
- Incluir ejemplos pr√°cticos y visuales cuando sea posible
- Estar basado en el contenido del libro proporcionado
- IMPORTANTE: Usa emoticonos apropiados para hacer el resumen m√°s visual, amigable y motivador
  Ejemplos: üìê üìè üìä üî¢ ‚ûï ‚ûñ ‚úñÔ∏è ‚ûó üéØ üí° ü§î ‚≠ê üìù ‚ú® üöÄ üìö üîç üí≠ ‚ö° üé® üìà üìâ üî∫ üîª ‚öñÔ∏è üé≤ ‚úÖ ‚ö†Ô∏è üí™ üëÄ üåü üìå üîë

Formato del resumen: Markdown con secciones bien diferenciadas."""

        messages = [
            {"role": "system", "content": "Eres un profesor de matem√°ticas experto en crear materiales de estudio did√°cticos y completos. Usa emoticonos para hacer el contenido m√°s visual y atractivo."},
            {"role": "user", "content": prompt}
        ]

        return self._call_chat_completion(messages, temperature=0.7)

    def generate_visual_scheme(self, exercise: str, context: str = None) -> str:
        """Generate a visual scheme using Mermaid diagram syntax"""

        prompt = f"""Genera un esquema visual usando sintaxis Mermaid para ayudar a resolver este ejercicio de matem√°ticas:

EJERCICIO:
{exercise}

Crea un diagrama Mermaid que:
- Represente visualmente la estructura del problema
- Muestre las relaciones entre los datos conocidos y desconocidos
- Sugiera el flujo l√≥gico de resoluci√≥n SIN resolverlo
- Use el tipo de diagrama m√°s apropiado (flowchart, graph, etc.)

REGLAS IMPORTANTES:
- NO incluyas c√°lculos espec√≠ficos ni resultados num√©ricos
- NO resuelvas el problema, solo muestra el camino
- Usa placeholders gen√©ricos como "Calcular X", "Aplicar f√≥rmula Y"
- El estudiante debe poder usar el diagrama para pensar por s√≠ mismo
- Mant√©n el diagrama orientativo, no resolutivo

FORMATO:
- Devuelve SOLO el c√≥digo Mermaid, sin explicaciones adicionales
- No incluyas bloques de c√≥digo markdown (```mermaid)
- Empieza directamente con el tipo de diagrama (ej: graph TD, flowchart LR, etc.)
- Usa etiquetas claras y concisas en espa√±ol

Ejemplo de formato esperado:
graph TD
    A[Datos del problema] --> B[Identificar qu√© se busca]
    B --> C[Aplicar concepto clave]
    C --> D[Realizar operaciones]
    D --> E[Verificar resultado]"""

        messages = [
            {"role": "system", "content": "Eres un experto en visualizaci√≥n de problemas matem√°ticos que crea diagramas Mermaid claros y did√°cticos."},
            {"role": "user", "content": prompt}
        ]

        response = self._call_chat_completion(messages, temperature=0.5)

        # Clean up response - remove markdown code blocks if present
        if '```mermaid' in response:
            response = response.split('```mermaid')[1].split('```')[0].strip()
        elif '```' in response:
            response = response.split('```')[1].split('```')[0].strip()

        return response.strip()
