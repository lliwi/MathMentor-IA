# MathMentor IA

**MathMentor IA** es una aplicaci√≥n educativa de vanguardia que utiliza Inteligencia Artificial para transformar el aprendizaje de matem√°ticas mediante pr√°ctica personalizada, correcci√≥n inteligente y gamificaci√≥n.

## Caracter√≠sticas Principales

- **Generaci√≥n de Ejercicios Personalizados** con IA basada en libros de texto espec√≠ficos
- **Selecci√≥n de Procedimientos/T√©cnicas** mediante checkboxes en lugar de texto libre para mejor evaluaci√≥n
- **Correcci√≥n Inteligente con Feedback Did√°ctico** que analiza tanto el resultado como el procedimiento
- **Sistema de Puntuaci√≥n y Gamificaci√≥n** para motivar el aprendizaje continuo
- **RAG (Retrieval-Augmented Generation)** para contextualizar ejercicios con el material de estudio
- **M√∫ltiples Motores de IA** soportados: OpenAI, DeepSeek, Ollama

## Stack Tecnol√≥gico

- **Backend:** Flask (Python)
- **Base de Datos:** PostgreSQL con pgvector
- **IA:** OpenAI, DeepSeek, Ollama
- **Containerizaci√≥n:** Docker Compose
- **Frontend:** Bootstrap 5 + JavaScript

## Instalaci√≥n y Configuraci√≥n

### Requisitos Previos

- Docker y Docker Compose
- Python 3.11+ (para desarrollo local sin Docker)
- Cuenta de OpenAI o DeepSeek (opcional, para funcionalidad IA)

### Configuraci√≥n R√°pida con Docker

1. **Clonar el repositorio:**
```bash
git clone <repository-url>
cd "MathMentor IA"
```

2. **Configurar variables de entorno:**
```bash
cp .env.example .env
```

Edita el archivo `.env` y configura:
- `SECRET_KEY`: Clave secreta para Flask
- `OPENAI_API_KEY`: Tu clave API de OpenAI (si usas OpenAI)
- `DEEPSEEK_API_KEY`: Tu clave API de DeepSeek (si usas DeepSeek)
- `ACTIVE_AI_ENGINE`: Motor activo (openai, deepseek, ollama)

3. **Iniciar la aplicaci√≥n:**
```bash
docker-compose up -d
```

4. **Aplicar √≠ndices de performance (RECOMENDADO):**
```bash
# Esperar a que los servicios est√©n listos (30 segundos)
docker-compose exec web python add_indexes.py
```

Este paso es **altamente recomendado** para optimizar la performance de b√∫squedas vectoriales y generaci√≥n de ejercicios.

5. **Acceder a la aplicaci√≥n:**
- Abrir navegador en: http://localhost:5000

### üöÄ Performance Optimizations

La aplicaci√≥n incluye m√∫ltiples optimizaciones de performance:
- **Redis Cache**: Cach√© de ejercicios y contextos RAG (70-90% reducci√≥n de latencia)
- **Cache Prefetching**: Precarga autom√°tica de contextos al acceder a `/student/practice`
- **Connection Pooling**: Pool de conexiones PostgreSQL optimizado
- **Batch Processing**: Procesamiento paralelo de embeddings (3-5x m√°s r√°pido)
- **Singleton Pattern**: Carga √∫nica del modelo de embeddings
- **HNSW Indexes**: √çndices vectoriales optimizados para b√∫squedas

Ver [PERFORMANCE_OPTIMIZATIONS.md](PERFORMANCE_OPTIMIZATIONS.md) para detalles completos y [CACHE_PREFETCHING.md](CACHE_PREFETCHING.md) para la funcionalidad de precarga.

### Migraci√≥n de Bases de Datos Existentes

Si ya tienes una instalaci√≥n anterior y quieres actualizar a la versi√≥n con selecci√≥n de procedimientos:

```bash
# Ejecutar script de migraci√≥n
docker-compose exec -T db psql -U mathmentor_user -d mathmentor < migrate_procedures.sql
```

Este script a√±ade las columnas necesarias (`available_procedures`, `expected_procedures`, `selected_procedures`) sin perder datos existentes.

### Usuarios de Prueba

Despu√©s de ejecutar `init_db.py`, tendr√°s estos usuarios:

**Administrador:**
- Usuario: `admin`
- Contrase√±a: `admin123`

**Estudiantes:**
- Usuario: `maria`, `juan`, `lucia`
- Contrase√±a: `estudiante123`

‚ö†Ô∏è **IMPORTANTE:** Cambia estas contrase√±as en producci√≥n.

## Uso de la Aplicaci√≥n

### Para Administradores

1. **Subir Libros (PDF):**
   - Ir a "Libros" ‚Üí "Subir Nuevo Libro"
   - Completar: T√≠tulo, Curso, Materia
   - Subir PDF (m√°x. 50MB)
   - El sistema procesar√° autom√°ticamente el PDF y extraer√° temas

2. **Asignar Temas a Estudiantes:**
   - Ir a "Estudiantes"
   - Seleccionar estudiante
   - Elegir curso y temas asignados
   - Guardar

3. **Configurar Motores de IA:**
   - Editar archivo `.env`
   - Configurar `ACTIVE_AI_ENGINE` y claves API

### Para Estudiantes

1. **Practicar:**
   - Ir a "Practicar"
   - Seleccionar dificultad
   - Generar ejercicio
   - Resolver y escribir respuesta
   - Seleccionar procedimientos/t√©cnicas utilizadas (checkboxes)
   - Enviar respuesta

2. **Sistema de Puntuaci√≥n:**
   - **+10 puntos:** Respuesta correcta
   - **+5 puntos:** Metodolog√≠a correcta (selecci√≥n correcta de procedimientos)
   - **+3 puntos:** Reintento exitoso tras feedback
   - **Bonus:** Rachas de 3, 5, 10, 15+ ejercicios

3. **Comprar Pistas:**
   - Costo: 5 puntos
   - Proporciona orientaci√≥n sin revelar la soluci√≥n

4. **Ver Progreso:**
   - Ir a "Marcador" para ver estad√≠sticas completas

## Arquitectura del Sistema

### Componentes Principales

1. **Flask Application** ([app.py](app.py))
   - Factory pattern con blueprints
   - Autenticaci√≥n con Flask-Login
   - Roles: Admin y Estudiante

2. **Modelos de Base de Datos** ([app/models/](app/models/))
   - Users, StudentProfiles, Books, Topics
   - Exercises, Submissions, StudentScores
   - DocumentEmbeddings (para RAG)

3. **Servicios** ([app/services/](app/services/))
   - **PDFProcessor:** Extracci√≥n y chunking de texto
   - **RAGService:** Embeddings y b√∫squeda sem√°ntica
   - **ScoringService:** L√≥gica de gamificaci√≥n

4. **Motores de IA** ([app/ai_engines/](app/ai_engines/))
   - Abstracci√≥n con clase base `AIEngine`
   - Implementaciones: OpenAI, DeepSeek, Ollama
   - Factory pattern para instanciaci√≥n

### Flujo de Trabajo RAG

El sistema RAG (Retrieval-Augmented Generation) se emplea en **3 puntos clave** de la aplicaci√≥n:

#### 1. Procesamiento y Almacenamiento de PDFs
**Ubicaci√≥n:** `app/admin/routes.py:113-125`

Cuando el administrador sube un libro PDF:

```python
pdf_processor = PDFProcessor(chunk_size=3000, chunk_overlap=200)
rag_service = RAGService()

# Extraer y dividir el texto en chunks
chunks = pdf_processor.process_pdf(book.pdf_path)

# Generar embeddings y almacenarlos en PostgreSQL con pgvector
rag_service.store_chunks(book.id, chunks)
```

**Proceso:**
- Extrae el texto del PDF p√°gina por p√°gina usando `pdfplumber`
- Divide el contenido en chunks (fragmentos de ~3000 caracteres con 200 de superposici√≥n)
- Genera embeddings vectoriales usando `sentence-transformers/all-MiniLM-L6-v2` (384 dimensiones)
- Almacena los chunks y sus embeddings en la tabla `document_embeddings` (PostgreSQL + pgvector)

#### 2. Generaci√≥n de Ejercicios
**Ubicaci√≥n:** `app/student/routes.py:78-90`

Cuando un estudiante solicita un nuevo ejercicio:

```python
# Recuperar contexto relevante del libro usando RAG
rag_service = RAGService()
context = rag_service.get_context_for_topic(topic_id, top_k=3)

# Generar ejercicio usando el contexto recuperado
ai_engine = AIEngineFactory.create()
exercise_data = ai_engine.generate_exercise(
    topic=topic.topic_name,
    context=context,  # ‚Üê Contexto recuperado v√≠a RAG
    difficulty=difficulty,
    course=profile.course
)
```

**Proceso:**
- Busca los 3 chunks m√°s relevantes del libro usando similitud coseno (operador `<=>` de pgvector)
- El contexto recuperado se env√≠a al modelo de IA (OpenAI/DeepSeek/Ollama)
- La IA genera un ejercicio basado en el contenido espec√≠fico del libro de texto

#### 3. Generaci√≥n de Pistas
**Ubicaci√≥n:** `app/student/routes.py:284-288`

Cuando un estudiante compra una pista (costo: 5 puntos):

```python
# Recuperar contexto relevante
rag_service = RAGService()
context = rag_service.get_context_for_topic(exercise.topic_id, top_k=2)

# Generar pista usando el contexto
hint = ai_engine.generate_hint(exercise.content, context)
```

**Proceso:**
- Recupera los 2 chunks m√°s relevantes del tema
- La IA genera una pista contextualizada basada en el contenido del libro
- Proporciona orientaci√≥n sin revelar la soluci√≥n completa

#### Arquitectura RAG

```
PDF ‚Üí PDFProcessor ‚Üí Chunks ‚Üí RAGService ‚Üí Embeddings ‚Üí PostgreSQL (pgvector)
                                                              ‚Üì
                                                     [b√∫squeda vectorial]
                                                              ‚Üì
Ejercicio/Pista ‚Üê AI Engine ‚Üê Contexto recuperado ‚Üê retrieve_context()
```

**Configuraci√≥n:**
- **Modelo de embeddings:** `sentence-transformers/all-MiniLM-L6-v2` (configurable v√≠a `EMBEDDING_MODEL` en `.env`)
- **Base de datos vectorial:** PostgreSQL 16 + extensi√≥n pgvector
- **M√©todo de similitud:** Distancia coseno (`<=>` operator)
- **Tama√±o de chunks:** 3000 caracteres con 200 de superposici√≥n

## Desarrollo

### Estructura del Proyecto

```
MathMentor IA/
‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py           # Application factory
‚îÇ   ‚îú‚îÄ‚îÄ admin/                # Admin blueprint
‚îÇ   ‚îú‚îÄ‚îÄ auth/                 # Authentication blueprint
‚îÇ   ‚îú‚îÄ‚îÄ student/              # Student blueprint
‚îÇ   ‚îú‚îÄ‚îÄ ai_engines/           # AI engine implementations
‚îÇ   ‚îú‚îÄ‚îÄ models/               # Database models
‚îÇ   ‚îú‚îÄ‚îÄ services/             # Business logic services
‚îÇ   ‚îú‚îÄ‚îÄ static/               # CSS, JS
‚îÇ   ‚îî‚îÄ‚îÄ templates/            # HTML templates
‚îú‚îÄ‚îÄ app.py                    # Application entry point
‚îú‚îÄ‚îÄ init_db.py                # Database initialization script
‚îú‚îÄ‚îÄ docker-compose.yml        # Docker services
‚îú‚îÄ‚îÄ Dockerfile                # Docker image
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îî‚îÄ‚îÄ .env.example              # Environment variables template
```

### Ejecutar Tests

```bash
pytest
```

### Migraciones de Base de Datos

```bash
# Inicializar migraciones
flask db init

# Crear migraci√≥n
flask db migrate -m "descripci√≥n"

# Aplicar migraci√≥n
flask db upgrade
```

## Comandos √ötiles

```bash
# Ver logs
docker-compose logs -f web

# Reiniciar servicios
docker-compose restart

# Detener servicios
docker-compose down

# Acceder al shell de Flask
docker-compose exec web flask shell

# Acceder a PostgreSQL
docker-compose exec db psql -U mathmentor_user -d mathmentor
```

## Configuraci√≥n de Motores de IA

### OpenAI

```env
ACTIVE_AI_ENGINE=openai
ACTIVE_AI_MODEL=gpt-4
OPENAI_API_KEY=sk-...
```

### DeepSeek

```env
ACTIVE_AI_ENGINE=deepseek
ACTIVE_AI_MODEL=deepseek-chat
DEEPSEEK_API_KEY=...
```

### Ollama (Local)

```env
ACTIVE_AI_ENGINE=ollama
ACTIVE_AI_MODEL=llama2
OLLAMA_BASE_URL=http://localhost:11434
```

## Troubleshooting

### Error: "pgvector extension not found"

Aseg√∫rate de usar la imagen `pgvector/pgvector:pg16` en docker-compose.yml

### Error al procesar PDF

- Verifica que el PDF no est√© protegido
- Tama√±o m√°ximo: 50MB
- Formato soportado: PDF

### Error de IA: "API key not configured"

Configura la clave API correspondiente en el archivo `.env`

## Contribuci√≥n

Este proyecto est√° en desarrollo activo. Las contribuciones son bienvenidas.

## Licencia

[Especifica tu licencia aqu√≠]

## Contacto

[Tu informaci√≥n de contacto]
